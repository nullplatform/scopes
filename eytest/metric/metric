#!/bin/bash
GROUP_BY=${GROUP_BY:-""}

# Validate required parameters
if [[ -z "$METRIC_NAME" ]]; then
  echo '{"metric":"","type":"","period_in_seconds":0,"unit":"","results":[]}'
  exit 1
fi

if [[ -z "$APPLICATION_ID" ]]; then
  echo '{"metric":"","type":"","period_in_seconds":0,"unit":"","results":[]}'
  exit 1
fi

if [[ -z "$PROM_URL" ]]; then
  echo '{"error":"PROM_URL is required. Please specify with PROM_URL environment variable"}'
  exit 1
fi

# Cross-platform date parsing function
parse_iso_date() {
  local iso_date="$1"
  
  # Remove T and milliseconds/Z for parsing
  local formatted_date=$(echo "$iso_date" | sed 's/T/ /' | sed 's/\.[0-9]*Z$//')
  
  # Try GNU date (Linux) first - test if -d flag works
  if date -u -d "$formatted_date" +%s 2>/dev/null; then
    return
  fi
  
  # Fall back to BSD date (macOS) - use -j -f format
  if date -j -u -f "%Y-%m-%d %H:%M:%S" "$formatted_date" +%s 2>/dev/null; then
    return
  fi
  
  # Final fallback
  echo "0"
}

get_metric_config() {
  case "$METRIC_NAME" in
    "http.error_rate")
      echo "gauge percent"
      ;;
    "http.response_time")
      echo "gauge seconds"
      ;;
    "http.rpm")
      echo "gauge count_per_minute"
      ;;
    "http.healthcheck_count")
      echo "gauge count"
      ;;
    "http.healthcheck_fail")
      echo "gauge count"
      ;;
    "system.cpu_usage_percentage")
      echo "gauge percent"
      ;;
    "system.cpu_usage_percentage_by_instance")
      echo "gauge percent"
      ;;
    "system.memory_usage_percentage")
      echo "gauge percent"
      ;;
    "system.used_memory_kb")
      echo "gauge kilobytes"
      ;;
    "cronjob.execution_count")
      echo "gauge count"
      ;;
    "cronjob.success_count")
      echo "gauge count"
      ;;
    "cronjob.failure_count")
      echo "gauge count"
      ;;
    "cronjob.last_execution_start")
      echo "gauge timestamp"
      ;;
    "cronjob.cpu_usage")
      echo "gauge percent"
      ;;
    "cronjob.memory_usage")
      echo "gauge bytes"
      ;;
    *)
      echo "gauge unknown"
      ;;
  esac
}

build_filters() {
  local filters=""

  # Add application_id filter
  if [[ -n "$APPLICATION_ID" ]]; then
    filters="application_id=\"$APPLICATION_ID\""
  fi

  # Add scope_id filter
  if [[ -n "$SCOPE_ID" ]]; then
    if [[ -n "$filters" ]]; then
      filters="$filters,"
    fi
    filters="${filters}scope_id=\"$SCOPE_ID\""
  fi

  if [[ -n "$DEPLOYMENT_ID" && "$DEPLOYMENT_ID" != "null" ]]; then
    if [[ -n "$filters" ]]; then
      filters="$filters,"
    fi
    filters="${filters}deployment_id=\"$DEPLOYMENT_ID\""
  fi

  echo "$filters"
}

# Build Prometheus query based on metric type
build_query() {
  local metric="$1"
  local filters="$2"
  local interval="$3"
  local groupBy="$GROUP_BY"

  if [[ "$groupBy" == "[]" || "$groupBy" == "" ]]; then
    groupBy=""
  fi

  # Replace instance_id with destination_pod in groupBy
  if [[ -n "$groupBy" ]]; then
    groupBy=$(echo "$groupBy" | sed 's/instance_id/destination_pod/g')
  fi

  case "$metric" in
    "http.healthcheck_count")
      if [[ -n "$groupBy" ]]; then
        echo "avg(np_kube_pod_container_status_ready_enriched{$filters}) by ($groupBy)"
      else
        echo "avg(np_kube_pod_container_status_ready_enriched{$filters})"
      fi
      ;;
    "http.healthcheck_fail")
      if [[ -n "$groupBy" ]]; then
        echo "sum(np_kube_pod_container_status_running_enriched{$filters}) by ($groupBy) - sum(np_kube_pod_container_status_ready_enriched{$filters}) by ($groupBy)"
      else
        echo "sum(np_kube_pod_container_status_running_enriched{$filters}) - sum(np_kube_pod_container_status_ready_enriched{$filters})"
      fi
      ;;
    "system.cpu_usage_percentage_by_instance")
      echo "avg(np_container_cpu_usage_percent_enriched{$filters}) by (pod)"
      ;;
    "system.memory_usage_percentage")
      if [[ -n "$groupBy" ]]; then
        echo "avg(np_container_memory_working_set_percent_enriched{$filters}) by ($groupBy)"
      else
        echo "avg(np_container_memory_working_set_percent_enriched{$filters})"
      fi
      ;;
    "system.cpu_usage_percentage")
      if [[ -n "$groupBy" ]]; then
        echo "avg(np_container_cpu_usage_percent_enriched{$filters}) by ($groupBy)"
      else
        echo "avg(np_container_cpu_usage_percent_enriched{$filters})"
      fi
      ;;
    "system.used_memory_kb")
      if [[ -n "$groupBy" ]]; then
        echo "avg(np_container_memory_working_set_bytes_enriched{$filters}) by ($groupBy) / 1024"
      else
        echo "avg(np_container_memory_working_set_bytes_enriched{$filters}) / 1024"
      fi
      ;;
    "http.response_time")
      if [[ -n "$groupBy" ]]; then
        echo "(sum(rate(np_request_duration_milliseconds_sum_enriched{$filters}[$interval])) by ($groupBy) / (sum(rate(np_request_duration_milliseconds_count_enriched{$filters}[$interval])) by ($groupBy) > 0)) or vector(0)"
      else
        echo "(sum(rate(np_request_duration_milliseconds_sum_enriched{$filters}[$interval])) / (sum(rate(np_request_duration_milliseconds_count_enriched{$filters}[$interval])) > 0)) or vector(0)"
      fi
      ;;
    "http.rpm")
      if [[ -n "$groupBy" ]]; then
        echo "ceil(avg_over_time((sum(rate(np_requests_total_enriched{$filters}[$interval])) by ($groupBy) * 60)[2m:10s]))"
      
      else
        echo "ceil(avg_over_time((sum(rate(np_requests_total_enriched{$filters}[$interval])) * 60)[2m:10s]))"
      fi
      ;;
    "http.error_rate")
      local base_filters="$filters"
      local error_filters="${filters},response_code=~\"[45]..\""
      if [[ -n "$groupBy" ]]; then
        echo "(sum(rate(np_requests_total_enriched{${error_filters}}[$interval])) by ($groupBy) / (sum(rate(np_requests_total_enriched{${base_filters}}[$interval])) by ($groupBy) > 0)) * 100 or vector(0)"
      else
        echo "(sum(rate(np_requests_total_enriched{${error_filters}}[$interval])) / (sum(rate(np_requests_total_enriched{${base_filters}}[$interval])) > 0)) * 100 or vector(0)"
      fi
      ;;
    "cronjob.execution_count")
      echo "sum by (scope_id) (label_replace(increase(kube_job_status_succeeded{job_name=~\"job-${SCOPE_ID}-.*\"}[$interval]) +increase(kube_job_status_failed{job_name=~\"job-${SCOPE_ID}-.*\"}[$interval]),\"scope_id\", \"\$1\", \"job_name\", \"job-([0-9]+)-.*\"))"
      ;;
    "cronjob.success_count")
      echo "sum by (scope_id) (label_replace(increase(kube_job_status_succeeded{job_name=~\"job-${SCOPE_ID}-.*\"}[$interval]), \"scope_id\", \"\$1\", \"job_name\", \"job-([0-9]+)-.*\"))"
      ;;
    "cronjob.failure_count")
      echo "sum by (scope_id) (label_replace(increase(kube_job_status_failed{job_name=~\"job-${SCOPE_ID}-.*\"}[$interval]), \"scope_id\", \"\$1\", \"job_name\", \"job-([0-9]+)-.*\"))"
      ;;
    "cronjob.cpu_usage")
      echo "avg(avg_over_time(container_cpu_usage_seconds_total{pod=~\"job-${SCOPE_ID}-.*\", container!=\"\", container!=\"POD\"}[$interval])) * 100"
      ;;
    "cronjob.memory_usage")
      echo "avg by (scope_id) (label_replace(container_memory_usage_bytes{pod=~\"job-${SCOPE_ID}-.*\", container!=\"\", container!=\"POD\"} / on(pod, container) kube_pod_container_resource_limits{resource=\"memory\", unit=\"byte\", pod=~\"job-${SCOPE_ID}-.*\"}, \"scope_id\", \"\$1\", \"pod\", \"job-([0-9]+)-.*\")) * 100"
      ;;
    *)
      echo "up{$filters}"  # Default query if metric not recognized
      ;;
  esac
}

# Query Prometheus and return the result
query_prometheus() {
  local query="$1"
  local start_time="$2"
  local end_time="$3"
  local step="$4"
  local url="${PROM_URL}/api/v1/query_range"
  local params="query=$(urlencode "$query")&start=$start_time&end=$end_time&step=${step}s"
  curl -s -G "$url" --data-urlencode "query=$query" --data-urlencode "start=$start_time" --data-urlencode "end=$end_time" --data-urlencode "step=${step}s"
}

urlencode() {
  local string="${1}"
  local strlen=${#string}
  local encoded=""
  local pos c o

  for (( pos=0 ; pos<strlen ; pos++ )); do
    c=${string:$pos:1}
    case "$c" in
      [-_.~a-zA-Z0-9] ) o="${c}" ;;
      * )               printf -v o '%%%02x' "'$c"
    esac
    encoded+="${o}"
  done
  echo "${encoded}"
}

# Handle START_TIME/END_TIME for cross-platform compatibility
if [[ -n "$START_TIME" && -n "$END_TIME" ]]; then
  # Convert ISO dates to Unix timestamps (cross-platform compatible)
  start_time=$(parse_iso_date "$START_TIME")
  now=$(parse_iso_date "$END_TIME")
  step=${PERIOD:-60}
  
  # Calculate interval like JavaScript service: period/60 + "m"
  if [[ -n "$PERIOD" && "$PERIOD" -gt 0 ]]; then
    interval_minutes=$((PERIOD / 60))
    if [[ $interval_minutes -lt 1 ]]; then
      interval_minutes=1
    fi
    # Use minimum 5m interval for HTTP metrics to ensure sufficient data points
    case "$METRIC_NAME" in
      "http.error_rate"|"http.response_time"|"http.rpm"|"http.healthcheck_count")
        if [[ $interval_minutes -lt 5 ]]; then
          interval_minutes=5
        fi
        ;;
    esac
    INTERVAL="${interval_minutes}m"
  else
    INTERVAL="5m"
  fi
else
  # Fallback to TIME_RANGE logic
  now=$(date +%s)
  case "$TIME_RANGE" in
    *h)
      hours=${TIME_RANGE%h}
      start_time=$((now - hours * 3600))
      ;;
    *m)
      minutes=${TIME_RANGE%m}
      start_time=$((now - minutes * 60))
      ;;
    *d)
      days=${TIME_RANGE%d}
      start_time=$((now - days * 86400))
      ;;
    *)
      start_time=$((now - 3600))
      ;;
  esac

  case "$INTERVAL" in
    *h)
      hours=${INTERVAL%h}
      step=$((hours * 3600))
      ;;
    *m)
      minutes=${INTERVAL%m}
      step=$((minutes * 60))
      ;;
    *s)
      step=${INTERVAL%s}
      ;;
    *)
      step=60
      ;;
  esac
fi

config=$(get_metric_config)
metric_type=$(echo $config | cut -d' ' -f1)
unit=$(echo $config | cut -d' ' -f2)

filters=$(build_filters)
query=$(build_query "$METRIC_NAME" "$filters" "$INTERVAL")

response=$(query_prometheus "$query" "$start_time" "$now" "$step")

transform_response() {
  local response="$1"
  local status=$(echo "$response" | jq -r '.status')

  if [[ "$status" != "success" ]]; then
    echo "[]"
    return
  fi

  local results=$(echo "$response" | jq '.data.result')

  if [[ "$results" == "[]" || "$results" == "null" ]]; then
    echo "[]"
    return
  fi

  echo "$results" | jq 'map({
    selector: (.metric | with_entries(if .key == "destination_pod" then .key = "instance_id" else . end)),
    data: .values | map({
      timestamp: (.[0] | tonumber | todate),
      value: (.[1] | tonumber)
    })
  })'
}

transformed_results=$(transform_response "$response")

echo "{\"metric\":\"$METRIC_NAME\",\"type\":\"$metric_type\",\"period_in_seconds\":$step,\"unit\":\"$unit\",\"results\":$transformed_results}"
