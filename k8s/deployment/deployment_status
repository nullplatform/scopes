#!/bin/bash

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'
BOLD='\033[1m'

DEPLOYMENT_ID=$(echo "$CONTEXT" | jq -r '.scope.active_deployment' 2>/dev/null || echo "")
NAMESPACE="${K8S_NAMESPACE}"
DEPLOYMENT_LABEL="deployment_id=$DEPLOYMENT_ID"
TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

print_success() {
    echo -e "${GREEN}✓${NC} $1"
}

print_error() {
    echo -e "${RED}✗${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}⚠${NC} $1"
}

print_info() {
    echo -e "${BLUE}ℹ${NC} $1"
}


# Deployment existence
if ! kubectl get deployment -l "$DEPLOYMENT_LABEL" -n "$NAMESPACE" &>/dev/null; then
    print_error "Deployment '$DEPLOYMENT_LABEL' not found in namespace '$NAMESPACE'"
    exit 1
fi

DEPLOYMENT_NAME=$(kubectl get deployment -l "$DEPLOYMENT_LABEL" -n "$NAMESPACE" -o jsonpath='{.items[0].metadata.name}')
print_success "Deployment found: $DEPLOYMENT_NAME"

# Pods status
MATCH_LABELS=$(kubectl get deployment -l "$DEPLOYMENT_LABEL" -n "$NAMESPACE" -o jsonpath='{.items[0].spec.selector.matchLabels}' | \
    jq -r 'to_entries | map("\(.key)=\(.value)") | join(",")')

PODS=$(kubectl get pods -n "$NAMESPACE" -l "$MATCH_LABELS" -o jsonpath='{.items[*].metadata.name}')
TOTAL_PODS=$(echo "$PODS" | wc -w)

# Get summary data
SUMMARY=$(kubectl get pods -n "$NAMESPACE" -l "$MATCH_LABELS" -o json | \
    jq -r --arg total "$TOTAL_PODS" '
        [.items | group_by(.status.phase)[] |
          {phase: .[0].status.phase, count: (length)}] |
        map("\(.phase) \(.count) (\((.count|tonumber / ($total|tonumber) * 100) | round)%)") |
        join(", ")
    ')

echo "Pods Summary ($TOTAL_PODS total): $SUMMARY"

# Replica status
DESIRED=$(kubectl get deployment -l "$DEPLOYMENT_LABEL" -n "$NAMESPACE" -o jsonpath='{.items[0].spec.replicas}')
READY=$(kubectl get deployment -l "$DEPLOYMENT_LABEL" -n "$NAMESPACE" -o jsonpath='{.items[0].status.readyReplicas}')

if [[ "${READY:-0}" == "$DESIRED" ]]; then
    print_success "All replicas are ready and healthy (${READY:-0}/$DESIRED)"
fi

# Check deployment conditions for common issues
DEPLOYMENT_CONDITIONS=$(kubectl get deployment -l "$DEPLOYMENT_LABEL" -n "$NAMESPACE" -o json | \
    jq -r '.items[0].status.conditions[]? | select(.status == "False") | "\(.type): \(.reason) - \(.message)"')

if [[ -n "$DEPLOYMENT_CONDITIONS" ]]; then
    echo ""
    print_warning "Deployment has issues:"
    echo "$DEPLOYMENT_CONDITIONS" | sed 's/^/  /'
fi

# Problematic pods - User friendly
PROBLEM_FOUND=false

# only check issues in a specific container inside the pod
CONTAINER_NAME=${CONTAINER_NAME:-application}

for POD in $PODS; do
  POD_JSON=$(kubectl get pod "$POD" -n "$NAMESPACE" -o json 2>/dev/null) || continue

  # Pod phase (context only; we won't trigger solely on this)
  POD_STATUS=$(jq -r '.status.phase // "Unknown"' <<<"$POD_JSON")

  # Extract the chosen container's status (if it exists)
  HAS_CONTAINER=$(jq -r --arg c "$CONTAINER_NAME" '
    [.status.containerStatuses[]? | select(.name==$c)] | length
  ' <<<"$POD_JSON")

  if [[ "$HAS_CONTAINER" -eq 0 ]]; then
    # Skip pods that don't have the target container
    continue
  fi

  READY_STATUS=$(jq -r --arg c "$CONTAINER_NAME" '
    (.status.containerStatuses[]? | select(.name==$c) | .ready) // false
  ' <<<"$POD_JSON")

  RESTART_COUNT=$(jq -r --arg c "$CONTAINER_NAME" '
    (.status.containerStatuses[]? | select(.name==$c) | .restartCount) // 0
  ' <<<"$POD_JSON")

  WAITING_REASON=$(jq -r --arg c "$CONTAINER_NAME" '
    (.status.containerStatuses[]? | select(.name==$c) | .state.waiting.reason) // ""
  ' <<<"$POD_JSON")

  WAITING_MESSAGE=$(jq -r --arg c "$CONTAINER_NAME" '
    (.status.containerStatuses[]? | select(.name==$c) | .state.waiting.message) // ""
  ' <<<"$POD_JSON")

  TERMINATED_REASON=$(jq -r --arg c "$CONTAINER_NAME" '
    (.status.containerStatuses[]? | select(.name==$c) | .state.terminated.reason) // ""
  ' <<<"$POD_JSON")

  EXIT_CODE=$(jq -r --arg c "$CONTAINER_NAME" '
    (.status.containerStatuses[]? | select(.name==$c) | .state.terminated.exitCode) // ""
  ' <<<"$POD_JSON")

  # Trigger ONLY on problems in the target container
  if [[ "$READY_STATUS" != "true" ]] || [[ "$RESTART_COUNT" -gt 0 ]] || [[ -n "$WAITING_REASON" ]] || [[ -n "$TERMINATED_REASON" ]]; then
    if [[ "$PROBLEM_FOUND" == false ]]; then
      print_warning "Issues detected in '$CONTAINER_NAME' containers:"
      PROBLEM_FOUND=true
    fi

    echo -e "${YELLOW}Pod: $POD${NC} (phase: $POD_STATUS) | Container: $CONTAINER_NAME | Ready: $READY_STATUS | Restarts: $RESTART_COUNT"

    if [[ -n "$WAITING_REASON" ]]; then
      echo -e "  ${RED}Problem:${NC} $WAITING_REASON"
      [[ -n "$WAITING_MESSAGE" ]] && echo "  Details: $WAITING_MESSAGE"
      case "$WAITING_REASON" in
        "ImagePullBackOff"|"ErrImagePull") echo "  → The image cannot be pulled from the registry";;
        "CrashLoopBackOff")                echo "  → The container is crashing repeatedly";;
        "CreateContainerConfigError")      echo "  → Configuration error (likely ConfigMap or Secret missing)";;
      esac
    fi

    if [[ -n "$TERMINATED_REASON" ]]; then
      echo -e "  ${RED}Container terminated:${NC} $TERMINATED_REASON${EXIT_CODE:+ (exit code: $EXIT_CODE)}"
      if [[ "$EXIT_CODE" == "137" ]]; then
        echo "  → Killed (OOMKilled / out of memory)"
      elif [[ "$EXIT_CODE" == "143" ]]; then
        echo "  → Received SIGTERM (graceful shutdown)"
      elif [[ -n "$EXIT_CODE" && "$EXIT_CODE" != "0" ]]; then
        echo "  → Application exited with error code $EXIT_CODE"
      fi
    fi

    # Recent events for this pod
    echo "  Recent events:"
    kubectl get events -n "$NAMESPACE" --field-selector involvedObject.name="$POD" \
      --sort-by='.lastTimestamp' -o json 2>/dev/null | \
      jq -r '.items[-3:] | .[] | "    [\(.type)] \(.reason): \(.message)"' || echo "    No events found"

    # Previous logs if restarted
    if [[ "$RESTART_COUNT" -gt 0 ]]; then
      echo "  Previous container logs (before restart, last 20 lines):"
      kubectl logs "$POD" -n "$NAMESPACE" -c "$CONTAINER_NAME" --previous --tail=20 2>&1 | sed 's/^/    /' \
        || echo "    No previous logs available"
    fi
  fi
done


if [[ "$PROBLEM_FOUND" == false ]]; then
    print_success "All pods are healthy"
fi


# Image info
echo "Container Image:"
kubectl get deployment -l "$DEPLOYMENT_LABEL" -n "$NAMESPACE" -o json | \
  jq -c '.items[0].spec.template.spec.containers | map({key: .name, value: .image}) | from_entries'

# Summary
if [[ "${READY:-0}" == "$DESIRED" ]] && [[ "$PROBLEM_FOUND" == false ]]; then
    print_success "Your deployment is healthy and running correctly"
else
    print_error "Your deployment has issues that need attention"
fi


# Gather all technical data
DEPLOYMENT_DATA=$(kubectl get deployment -l "$DEPLOYMENT_LABEL" -n "$NAMESPACE" -o json)
PODS_DATA=$(kubectl get pods -n "$NAMESPACE" -l "$MATCH_LABELS" -o json)
EVENTS_DATA=$(kubectl get events -n "$NAMESPACE" --field-selector involvedObject.name="$DEPLOYMENT_NAME" --sort-by='.lastTimestamp' -o json 2>/dev/null)
REPLICASETS_DATA=$(kubectl get rs -n "$NAMESPACE" -l "$MATCH_LABELS" -o json)

# Current ReplicaSet
CURRENT_RS=$(echo "$REPLICASETS_DATA" | jq -r '.items | sort_by(.metadata.creationTimestamp) | reverse | .[0].metadata.name')

# Build comprehensive DevOps context
DEVOPS_CONTEXT=$(jq -n \
  --arg timestamp "$TIMESTAMP" \
  --arg namespace "$NAMESPACE" \
  --arg deployment "$DEPLOYMENT_NAME" \
  --arg deployment_id "$DEPLOYMENT_ID" \
  --arg current_rs "$CURRENT_RS" \
  --argjson deployment_data "$DEPLOYMENT_DATA" \
  --argjson pods_data "$PODS_DATA" \
  --argjson events_data "$EVENTS_DATA" \
  --argjson replicasets_data "$REPLICASETS_DATA" \
  '{
    timestamp: $timestamp,
    cluster: {
      namespace: $namespace
    },
    deployment: {
      name: $deployment,
      deployment_id: $deployment_id,
      labels: $deployment_data.items[0].metadata.labels,
      annotations: $deployment_data.items[0].metadata.annotations,
      replicas: {
        desired: $deployment_data.items[0].spec.replicas,
        ready: $deployment_data.items[0].status.readyReplicas,
        available: $deployment_data.items[0].status.availableReplicas,
        updated: $deployment_data.items[0].status.updatedReplicas
      },
      strategy: $deployment_data.items[0].spec.strategy,
      conditions: $deployment_data.items[0].status.conditions,
      currentReplicaSet: $current_rs
    },
    containers: [
      $deployment_data.items[0].spec.template.spec.containers[] | {
        name: .name,
        image: .image,
        imagePullPolicy: .imagePullPolicy,
        resources: .resources,
        livenessProbe: .livenessProbe,
        readinessProbe: .readinessProbe,
        startupProbe: .startupProbe,
        env: [.env[]? | {name: .name, valueFrom: .valueFrom}],
        volumeMounts: .volumeMounts
      }
    ],
    volumes: $deployment_data.items[0].spec.template.spec.volumes,
    pods: [
      $pods_data.items[] | {
        name: .metadata.name,
        phase: .status.phase,
        node: .spec.nodeName,
        ip: .status.podIP,
        startTime: .status.startTime,
        conditions: .status.conditions,
        containerStatuses: [
          .status.containerStatuses[]? | {
            name: .name,
            ready: .ready,
            restartCount: .restartCount,
            state: .state,
            lastState: .lastState,
            image: .image,
            imageID: .imageID
          }
        ]
      }
    ],
    replicaSets: [
      $replicasets_data.items[] | {
        name: .metadata.name,
        replicas: .status.replicas,
        readyReplicas: .status.readyReplicas,
        created: .metadata.creationTimestamp,
        revision: .metadata.annotations["deployment.kubernetes.io/revision"]
      }
    ] | sort_by(.created) | reverse | .[0:5],
    events: [
      $events_data.items[]? | {
        type: .type,
        reason: .reason,
        message: .message,
        count: .count,
        firstTimestamp: .firstTimestamp,
        lastTimestamp: .lastTimestamp,
        involvedObject: .involvedObject.name
      }
    ] | sort_by(.lastTimestamp) | reverse | .[0:20]
  }')

echo "$DEVOPS_CONTEXT" | jq -c '.'
